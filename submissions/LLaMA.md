# LLaMA

## Model Details

- Name: [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) üìö
- Model Size: 65B
- Dataset: 1.4 trillion tokens drawn from publicly available data sources and text from 20 different languages
- Input/Output Format: Text
- Research Field: Deep Learning, Natural Language Processing
- Contains an Impact Assessment: Yes
- Associated Risks: ‚ò£Ô∏è Disinformation, Algorithmic Discrimination, Social Engineering, Environmental Impacts ‚ò£Ô∏è
- Date of Publication: 2/27/2023
- Organization: [Meta AI](https://ai.meta.com/) (Public Company)
- Country/Origin: United States of America
- License: LLaMA 2 Community License Agreement
- Publication: [LLaMA: A foundational, 65-billion-parameter large language model](https://arxiv.org/abs/2302.13971)

## Description

[LLaMA](https://ai.meta.com/blog/large-language-model-llama-meta-ai/) is a collection of foundation language models ranging from 7B to 65B parameters, trained on over a trillion tokens of publicly available data. According to Meta AI, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B.

LLaMA models are GPT-style autoregressive transformers trained on a substantially more significant amount of data than other language models, following the [Chinchilla scaling laws](https://arxiv.org/abs/2203.15556), i.e., a set of empirical rules that describe the optimal trade-off between model size and training data for LLMs. LLaMA models can perform several NLP tasks in a zero/few-shot fashion, like closed-book questions and answering, mathematical reasoning, reading comprehension, and code generation.

LLaMA models were released under a noncommercial license focused on research use cases. [Access to the models](https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform) is granted on a case-by-case basis to academic researchers; those affiliated with organizations in government, civil society, and academia; and industry research laboratories around the world.

## Organization

[Meta AI](https://ai.facebook.com/) is the AI research division of Meta Platforms, Inc., known as Meta] and formerly Facebook, Inc. Meta is an American multinational technology conglomerate based in Menlo Park, California. Meta AI started as Facebook Artificial Intelligence Research (FAIR), announced in September 2013, and initially directed by [Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun "Yann LeCun").  
  
When it comes to matters of AI Ethics, [Meta AI expresses](https://ai.meta.com/about/) that "_Our commitment to responsible AI is driven by the belief that everyone should have equitable access to information, services, and opportunities_". Meta AI also claims to adhere to Meta's core principles: Privacy and security, Fairness and inclusion, Robustness and safety, Transparency and control, Accountability and governance, among other key principles.

